{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1atuwy-UUXSbjtMo3jaPZgpE1Rpwb7NwH","timestamp":1748802627691}],"machine_shape":"hm","mount_file_id":"1ZYy84XRB_h0BkyNdXITtmQl1FH5CTc1M","authorship_tag":"ABX9TyONxDyeIPmzt7jtFabOHkuj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Purpose:** Perform Feature Extraction using TSFRESH for Kepler Exoplanet Lightcurves\n","\n","**Goals:**\n","1. Filter Flux Observations to remove outliers\n","2. De-Trend the lightcurves using polynomial smoothing (Savitsky-Golay Filter)\n","3. Normalize the ligtcurves\n","4. Extract Features using the TSFRESH library\n","\n","**Input:** Exoplanet Lightcurves chosen by availability and data quality metrics\n","\n","**Output:** CSV File containing a list of Time Series Features for use by AI/ML Models."],"metadata":{"id":"gA-TeCtdUJoW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wac8pXGjxET9"},"outputs":[],"source":["###################################################################################\n","# Feature Extraction using TSFRESH for Kepler Exoplanet Lightcurves\n","###################################################################################\n","!pip install lightkurve astroquery pandas numpy tqdm  xgboost\n","!bash pip install --upgrade astroquery\n","#!pip install tsfel\n","!pip install stumpy\n","!pip install tsfresh\n","!pip install batman-package\n"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import tsfresh\n","from tsfresh import extract_features, select_features\n","from tsfresh.utilities.dataframe_functions import impute\n","from tsfresh.feature_extraction import ComprehensiveFCParameters, EfficientFCParameters\n","#import tsfel\n","#from tsfel import time_series_features_extractor, get_features_by_domain\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n","from pathlib import Path\n","import lightkurve as lk\n","from lightkurve import LightCurve\n","#import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","import stumpy\n","from multiprocessing import Process, Queue\n","import time\n","\n","\n","\n","#import lightkurve as lk\n","#from lightkurve import LightCurve\n","\n"],"metadata":{"id":"W5CqNhT9xz1p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Define paths and constants\n","\n","ROOT  = Path(\"/content/drive/MyDrive/Berkeley_AIML/Capstone/lightcurves\")\n","#EXOPLANET_INPUT_CURVES_PATH = ROOT / \"chosen_exoplanet_curves\"\n","SIMULATED_CURVES_PATH       = ROOT / \"simcurves2\"\n","ANCILLARY                   = ROOT / \"ancillary\"\n","OUTPUT_PATH                 = ROOT / \"orbital_prediction_simcurve_XGB_model1\"\n","CHOSEN_EXOPLANET_CURVES     = ROOT / \"chosen_exoplanet_curves\"\n","CHOSEN_EXOPLANET_CLEAN_CURVES     = ROOT / \"chosen_exoplanet_clean_curves\"\n","\n","# Kepler long cadence parameters for number of observations per quarter\n","CADENCE_MIN = 29.4  # minutes\n","CADENCE_SEC = CADENCE_MIN * 60  # seconds\n","DAYS_PER_QUARTER = 90\n","POINTS_PER_QUARTER = int(DAYS_PER_QUARTER * 24 * 60 / CADENCE_MIN)  # ~4,416\n","NUM_QUARTERS = 4\n","TOTAL_POINTS = POINTS_PER_QUARTER * NUM_QUARTERS  # ~17,664\n","# Array of time values for 4 quarters of 90 days each at a cadence of 29.4 minutes approx.\n","TIME_ARRAY = np.linspace(0, DAYS_PER_QUARTER * NUM_QUARTERS, TOTAL_POINTS)\n","\n","\n","# Parameters of Log-normal distribution of ORBITAL PERIOD (from EDA_ZERO.ipynb) fitted to known Kepler long cadence lightcurves with exoplanets\n","ORB_PERIOD_LOGNORM_SHAPE = 1.3330          # sigma\n","ORB_PERIOD_LOGNORM_LOC = 0.0               # location, must be 0\n","ORB_PERIOD_LOGNORM_SCALE = 11.5893         # exp(mu)\n","\n","# Parameters of Log-normal distribution of STELLAR RADII (from EDA_ZERO.ipynb) fitted to known Kepler long cadence lightcurves with exoplanets\n","ST_RAD_LOGNORM_SHAPE = 0.298937          # sigma\n","ST_RAD_LOGNORM_LOC = 0.0               # location, must be 0\n","ST_RAD_LOGNORM_SCALE = 0.961700         # exp(mu)\n","\n","# Parameters of Normal distribution of STELLAR MASSES (from EDA_ZERO.ipynb) fitted to known Kepler long cadence lightcurves with exoplanets\n","ST_MASS_LOC = 0.963588   # mu\n","ST_MASS_SCALE = 0.193144 # sigma\n","\n","os.makedirs(OUTPUT_PATH, exist_ok=True)\n","os.makedirs(SIMULATED_CURVES_PATH, exist_ok=True)"],"metadata":{"id":"yEsZYytdtOwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clean and store resampled Kepler lightcurves\n","i=1\n","max_files = len(os.listdir(CHOSEN_EXOPLANET_CURVES))\n","for filename in os.listdir(CHOSEN_EXOPLANET_CURVES):\n","    if filename.endswith(\"_4q_curve.csv\"):\n","      file_path = os.path.join(CHOSEN_EXOPLANET_CURVES, filename)\n","\n","      # Load CSV into DataFrame\n","      lc_df = pd.read_csv(file_path)\n","      # Extract planet name\n","      planet_name = filename.replace(\"_4q_curve.csv\", \"\")\n","      planet_name = planet_name.replace(\"_\", \" \")\n","      # Normalize and De-Trend the Lightcurve\n","      lc_df = process_lightcurve(planet_name, lc_df)\n","      # Drop rows where 'flux' is NaN (i.e., was originally non-numeric)\n","\n","      #if 'flux' in lc_df.columns:\n","      #    lc_df['flux'] = pd.to_numeric(lc_df['flux'], errors='coerce')\n","      #    lc_df = lc_df.dropna(subset=['flux'])\n","      lc_df = lc_df.rename(columns={'flux': 'value'})\n","\n","      lc_df['planet_name'] = planet_name  # required for column_id\n","      lc_df.to_csv(os.path.join(CHOSEN_EXOPLANET_CLEAN_CURVES, f\"{planet_name}_cleaned_4q_curve.csv\"), index=False)\n","      i=i+1\n","      if i % 20 == 0:\n","        print(f\"Processed {i} Planets of {max_files} \")\n","\n","print(f\"Completed {i} Planets of {max_files} \")"],"metadata":{"id":"z4QJ95O4XX61"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**NOTE:** The above Code timed out repeatedly due to Google Drive Quota violations, processing only a portion of the light curves.  hence I had to write code to check for the presence of Cleaned Curve, and if not, to repeat the process and extract features immediately afterwards."],"metadata":{"id":"34ybHwq-Xir-"}},{"cell_type":"code","source":["from lightkurve import LightCurve\n","import numpy as np\n","import pandas as pd\n","from scipy.interpolate import interp1d\n","\n","def process_lightcurve(planet_name, lc_df):\n","    try:\n","        # Clean flux column\n","        lc_df['flux'] = pd.to_numeric(lc_df['flux'], errors='coerce')\n","        lc_df = lc_df.dropna(subset=['flux'])\n","        lc_df = lc_df.sort_values('time')\n","\n","        # Build LightCurve object\n","        lc = LightCurve(time=lc_df['time'].values, flux=lc_df['flux'].values)\n","        lc = lc.remove_nans()\n","        lc = lc.flatten(window_length=401, sigma=2)\n","        lc = lc.remove_outliers(sigma=5)\n","        lc = lc.normalize().remove_nans()\n","        lc = lc.fill_gaps()\n","\n","        # Check for uniform cadence\n","        dt = np.diff(lc.time.value)\n","        median_dt = np.median(dt)\n","        if not np.allclose(dt, median_dt, rtol=1e-2):\n","            # Interpolation needed\n","            print(f\"           Resampling {planet_name} to uniform cadence...\")\n","\n","            uniform_time = np.arange(lc.time.value[0], lc.time.value[-1], median_dt)\n","            interp_func = interp1d(lc.time.value, lc.flux.value, kind='linear', bounds_error=False, fill_value='extrapolate')\n","            uniform_flux = interp_func(uniform_time)\n","\n","            lc = LightCurve(time=uniform_time, flux=uniform_flux)\n","\n","        # Final clean DataFrame for TSFresh\n","        cleaned_df = lc.to_pandas().reset_index()\n","\n","        return cleaned_df\n","\n","    except Exception as e:\n","        print(f\"Error processing lightcurve: {e}\")\n","        return pd.DataFrame()\n"],"metadata":{"id":"jUIN5mdLU5nU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RWO8WoM-UOKO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_with_timeout(planet_name, lc_df, queue):\n","    try:\n","        cleaned_df = process_lightcurve(planet_name, lc_df)\n","        cleaned_df['planet_name'] = planet_name\n","        cleaned_df = cleaned_df.rename(columns={'flux': 'value'})\n","        queue.put(cleaned_df)\n","    except Exception as e:\n","        print(f\"Error during processing {planet_name}: {e}\")\n","        queue.put(None)"],"metadata":{"id":"48SGRdzicCJW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Define directories\n","# Assume these are set: CHOSEN_EXOPLANET_CURVES, CHOSEN_EXOPLANET_CLEAN_CURVES\n","\n","i = 1\n","max_files = len([f for f in os.listdir(CHOSEN_EXOPLANET_CURVES) if f.endswith(\"_4q_curve.csv\")])\n","\n","for filename in os.listdir(CHOSEN_EXOPLANET_CURVES):\n","    if filename.endswith(\"_4q_curve.csv\"):\n","        # Get raw planet name\n","        planet_name = filename.replace(\"_4q_curve.csv\", \"\")\n","        raw_planet_name = planet_name.replace(\"_\", \" \")\n","\n","        # Check if cleaned file already exists\n","        cleaned_filename = f\"{planet_name}_cleaned_4q_curve.csv\"\n","        cleaned_path = os.path.join(CHOSEN_EXOPLANET_CLEAN_CURVES, cleaned_filename)\n","        if os.path.exists(cleaned_path):\n","            print(f\"Skipping {planet_name} (already processed)\")\n","            continue\n","\n","        file_path = os.path.join(CHOSEN_EXOPLANET_CURVES, filename)\n","\n","        try:\n","            lc_df = pd.read_csv(file_path)\n","\n","            # Timeout-safe processing\n","            queue = Queue()\n","            p = Process(target=process_with_timeout, args=(raw_planet_name, lc_df, queue))\n","            p.start()\n","            p.join(timeout=40)  # timeout in seconds\n","\n","            if p.is_alive():\n","                print(f\"Timeout while processing {planet_name}, skipping.\")\n","                p.terminate()\n","                p.join()\n","                continue\n","\n","            result = queue.get()\n","            if result is not None and not result.empty:\n","                result.to_csv(cleaned_path, index=False)\n","                i += 1\n","                if i % 20 == 0:\n","                    print(f\"Processed {i} Planets of {max_files}\")\n","            else:\n","                print(f\"Failed to process {planet_name} (no data returned)\")\n","\n","        except Exception as e:\n","            print(f\"Error reading file {filename}: {e}\")\n","\n","print(f\"Completed {i} Planets of {max_files}\")\n"],"metadata":{"id":"MvR_ACoKb1qp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##########################\n","# Feature Extraction Code\n","##########################\n","import logging\n","from scipy.stats import lognorm\n","logging.getLogger('tsfresh.feature_extraction.settings').setLevel(logging.ERROR)\n","\n","batch_size = 50\n","\n","i=0\n","features = []\n","\n","kepler_curve_periods = os.path.join(OUTPUT_PATH, \"kepler_clean_curve_tsfresh_features.csv\")\n","kepler_curve_features_filename = os.path.join(OUTPUT_PATH, \"kepler_clean_curve_tsfresh_features.csv\")\n","print(kepler_curve_features_filename)\n","\n","# Ensure fresh output files\n","if os.path.exists(kepler_curve_features_filename):\n","    os.remove(kepler_curve_features_filename)\n","\n","print(\"Extracting TSFresh features for Chosen Cleaned Kepler Exoplanets\")\n","for filename in os.listdir(CHOSEN_EXOPLANET_CLEAN_CURVES):\n","    if filename.endswith(\"_cleaned_4q_curve.csv\"):\n","      file_path = os.path.join(CHOSEN_EXOPLANET_CLEAN_CURVES, filename)\n","\n","      # Load CSV into DataFrame\n","      lc_df = pd.read_csv(file_path)\n","      # Extract planet name\n","      planet_name = filename.replace(\"_cleaned_4q_curve.csv\", \"\")\n","      planet_name = planet_name.replace(\"_\", \" \")\n","\n","      if 'flux' in lc_df.columns:\n","        lc_df = lc_df.rename(columns={'flux': 'value'})\n","\n","      #lc_df['planet_name'] = planet_name  # required for column_id\n","      feats = extract_features(\n","          lc_df,\n","          column_id='planet_name',\n","          column_sort='time',\n","          column_value='value',\n","          default_fc_parameters=EfficientFCParameters(),\n","          disable_progressbar=True,\n","          show_warnings=False,\n","          n_jobs=0\n","      )\n","      feats.index.name = 'planet_name'\n","      features.append(feats)\n","      #if (i + 1) % batch_size == 0:\n","      #  print(f'Extracted Features for  Planet {i+1}: {planet_name}')\n","\n","      i=i+1\n","      # Process and save batch\n","      if (i + 1) % batch_size == 0:\n","          print(f\"Processing batch ending at Planet {i + 1}\")\n","          features_df = pd.concat(features)\n","          features_df.reset_index(inplace=True)  # makes 'planet_name' a column\n","\n","          features_df.to_csv(kepler_curve_features_filename, mode='a', header=True, index=False)\n","\n","          # Clear batch memory\n","          features.clear()\n","\n","print(f\"Finished Generating {i + 1} TSFresh features for chosen Kepler curves\")\n","print(f\"Features saved to {kepler_curve_features_filename}\")"],"metadata":{"id":"v_LqPL9mDeCW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca3d9a25-3d54-486b-deb8-a85dbef3883e","executionInfo":{"status":"ok","timestamp":1751753379923,"user_tz":240,"elapsed":2381871,"user":{"displayName":"Prem Isaac","userId":"04442162912535875359"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Berkeley_AIML/Capstone/lightcurves/orbital_prediction_simcurve_XGB_model1/kepler_clean_curve_tsfresh_features.csv\n","Extracting TSFresh features for Chosen Cleaned Kepler Exoplanets\n","Processing batch ending at Planet 50\n","Processing batch ending at Planet 100\n","Processing batch ending at Planet 150\n","Processing batch ending at Planet 200\n","Processing batch ending at Planet 250\n","Processing batch ending at Planet 300\n","Processing batch ending at Planet 350\n","Processing batch ending at Planet 400\n","Processing batch ending at Planet 450\n","Processing batch ending at Planet 500\n","Processing batch ending at Planet 550\n","Processing batch ending at Planet 600\n","Processing batch ending at Planet 650\n","Processing batch ending at Planet 700\n","Processing batch ending at Planet 750\n","Processing batch ending at Planet 800\n","Finished Generating 802 TSFresh features for chosen Kepler curves\n","Features saved to /content/drive/MyDrive/Berkeley_AIML/Capstone/lightcurves/orbital_prediction_simcurve_XGB_model1/kepler_clean_curve_tsfresh_features.csv\n"]}]}]}